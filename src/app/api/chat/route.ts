// Edge runtime provides native fetch

export const runtime = 'edge';

export async function POST(req: Request) {
  const { messages } = await req.json();

  // Perplexity APIëŠ” system ë©”ì‹œì§€ ì´í›„ë¡œ user/assistantê°€ ë²ˆê°ˆì•„ê°€ë©° ë“±ìž¥í•´ì•¼ í•©ë‹ˆë‹¤.
  // useChatì´ ì „ë‹¬í•˜ëŠ” messages ë°°ì—´ì—ëŠ” ì‚¬ìš©ìžê°€ ì—°ì†ìœ¼ë¡œ ìž…ë ¥í•œ ê²½ìš° user ë©”ì‹œì§€ê°€ ì—°ë‹¬ì•„ ìžˆì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ
  // ë™ì¼ roleì´ ì—°ì†ë  ê²½ìš° ë‚´ìš©ì„ í•©ì³ í•˜ë‚˜ë¡œ ë³‘í•©í•œ í›„ ì „ì†¡í•©ë‹ˆë‹¤.

  const mergedMessages = [] as typeof messages;
  for (const msg of messages) {
    if (mergedMessages.length > 0 && mergedMessages[mergedMessages.length - 1].role === msg.role) {
      // ê°™ì€ role: ë‚´ìš© ì´ì–´ë¶™ì´ê¸° (ì¤„ë°”ê¿ˆ)
      mergedMessages[mergedMessages.length - 1].content += '\n' + msg.content;
    } else {
      mergedMessages.push({ ...msg });
    }
  }

  const response = await fetch('https://api.perplexity.ai/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`
    },
    body: JSON.stringify({
      model: 'sonar-pro',
      stream: true,
      messages: [
        {
          role: 'system',
          content: `ë‹¹ì‹ ì€ Jung's Research Assistantìž…ë‹ˆë‹¤. ì—°êµ¬ìžì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ë©°, ë…¼ë¬¸ ê²€ìƒ‰, ìš”ì•½, ì¸ìš©, ì°¸ê³ ë¬¸í—Œ ì •ë¦¬ë¥¼ ë„ì™€ì¤ë‹ˆë‹¤. ì •ë³´ë¥¼ ì°¾ì„ ë•Œì—ëŠ” í•œêµ­ ë¿ ì•„ë‹ˆë¼ êµ­ì œì ìœ¼ë¡œ ìœ ëª…í•œ ì •ë³´ë“¤ì„ ì°¾ìœ¼ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹ ê°€ì´ë“œë¼ì¸:**
1. ì‘ë‹µì„ ë…¼ë¦¬ì ì¸ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•˜ì„¸ìš”
2. ê° ì„¹ì…˜ì—ëŠ” ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ í¬í•¨í•œ ì œëª©ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: ðŸ”¬ ì—°êµ¬ ë™í–¥, ðŸ“Š ì£¼ìš” ë°œê²¬, ðŸ’¡ ì‹œì‚¬ì  ë“±)
3. ê° ì„¹ì…˜ ë‚´ìš©ì€ ë¶ˆë¦¿ í¬ì¸íŠ¸(â€¢)ë¡œ ì •ë¦¬í•˜ì„¸ìš”
4. ì„¹ì…˜ ê°„ì—ëŠ” ë¹ˆ ì¤„ì„ ë‘ì–´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”
5. ì¤‘ìš”í•œ ì •ë³´ëŠ” **ë³¼ë“œì²´**ë¡œ ê°•ì¡°í•˜ì„¸ìš”
6. í•„ìš”ì‹œ í‘œë‚˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì •ë³´ë¥¼ ì •ë¦¬í•˜ì„¸ìš”

**ì˜ˆì‹œ ì‘ë‹µ êµ¬ì¡°:**
ðŸ”¬ **ì£¼ìš” ì—°êµ¬ ê²°ê³¼**
â€¢ ì²« ë²ˆì§¸ ì£¼ìš” ë°œê²¬
â€¢ ë‘ ë²ˆì§¸ ì£¼ìš” ë°œê²¬

ðŸ“Š **í†µê³„ ë° ë°ì´í„°**
â€¢ ê´€ë ¨ ìˆ˜ì¹˜ë‚˜ í†µê³„
â€¢ ë¹„êµ ë¶„ì„ ê²°ê³¼

ðŸ’¡ **ì‹œì‚¬ì  ë° ê²°ë¡ **
â€¢ ì—°êµ¬ì˜ ì˜ë¯¸
â€¢ í–¥í›„ ì „ë§

ì‚¬ìš©ìžê°€ ê°„ë‹¨í•œ ì¸ì‚¬(ì˜ˆ: ì•ˆë…•, ì•ˆë…•í•˜ì„¸ìš” ë“±)ë¥¼ ìž…ë ¥í•˜ë©´, ì‚¬ì „ì  ì˜ë¯¸ ì„¤ëª…ì´ ì•„ë‹Œ ë”°ëœ»í•œ ì¸ì‚¬ë¡œ ê°„ë‹¨ížˆ ì‘ë‹µí•˜ì„¸ìš”. ì˜ˆ) "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"`
        },
        ...mergedMessages
      ],
      options: {
        citations: true  // Enable citations in the response
      }
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    const msg = `Request to Perplexity failed (${response.status}): ${errorText}`;
    return new Response(msg, {
      status: 200,
      headers: { 'Content-Type': 'text/plain; charset=utf-8' },
    });
  }

  // Perplexity returns an SSE stream (lines starting with "data:")
  const encoder = new TextEncoder();
  const decoder = new TextDecoder();

  // Accumulators for citations and search results emitted by Perplexity.
  const collectedCitations: any[] = []; // May contain citation identifiers or URLs or objects depending on model
  const collectedSearchResults: any[] = []; // Objects containing { title, url, ... }

  let remainder = '';

  const transformStream = new TransformStream({
    transform(chunk, controller) {
      // Append new chunk to any leftover data from previous chunk
      const text = remainder + decoder.decode(chunk, { stream: true });

      // Split into lines; the last element may be incomplete
      const parts = text.split('\n');
      remainder = parts.pop() ?? '';

      for (const line of parts) {
        // Perplexity sends "data:" JSON chunks and finally "data: [DONE]".
        if (line.startsWith('data:')) {
          // Handle the [DONE] sentinel â€“ we'll flush in the separate flush() callback.
          if (line.trim() === 'data:[DONE]' || line.trim() === 'data: [DONE]') {
            continue;
          }

          try {
            // Remove the leading 'data:' prefix and any whitespace after it.
            const jsonStr = line.slice(5).trimStart();
            const data = JSON.parse(jsonStr);

            // Stream the partial content tokens to the client.
            const deltaContent = data.choices?.[0]?.delta?.content;
            if (deltaContent) {
              controller.enqueue(encoder.encode(deltaContent));
            }

            // Accumulate citations if they appear inside delta (rare) or top-level.
            const deltaCitations = data.choices?.[0]?.delta?.citations ?? data.citations;
            if (Array.isArray(deltaCitations) && deltaCitations.length > 0) {
              collectedCitations.push(...deltaCitations);
            }

            // Accumulate search_results if present (title + url information).
            if (Array.isArray(data.search_results) && data.search_results.length > 0) {
              collectedSearchResults.push(...data.search_results);
            }
          } catch (e) {
            // Ignore JSON parse errors which can happen on partial chunks.
          }
        }
      }
    },

    flush(controller) {
      // Process any leftover data in remainder
      if (remainder.startsWith('data:')) {
        try {
          const data = JSON.parse(remainder.slice(5).trimStart());
          if (data.choices?.[0]?.delta?.content) {
            controller.enqueue(encoder.encode(data.choices[0].delta.content));
          }
          const deltaCitations = data.choices?.[0]?.delta?.citations ?? data.citations;
          if (Array.isArray(deltaCitations) && deltaCitations.length > 0) collectedCitations.push(...deltaCitations);
          if (Array.isArray(data.search_results) && data.search_results.length > 0) collectedSearchResults.push(...data.search_results);
        } catch (e) {
          // ignore
        }
      }

      // Build a unique list of citations with titles & URLs if possible.
      // Strategy: If search_results available, use them for rich info;
      // otherwise treat collectedCitations as URLs and render those.

      const unique: { url: string; title: string }[] = [];

      if (collectedSearchResults.length > 0) {
        for (const sr of collectedSearchResults) {
          if (!sr.url) continue;
          if (unique.some((u) => u.url === sr.url)) continue;
          unique.push({ url: sr.url, title: sr.title || sr.url });
        }
      } else if (collectedCitations.length > 0) {
        for (const cite of collectedCitations) {
          const url = typeof cite === 'string' ? cite : cite?.url;
          if (!url) continue;
          if (unique.some((u) => u.url === url)) continue;
          unique.push({ url, title: url });
        }
      }

      if (unique.length > 0) {
        const citationLines = unique.map((c, idx) => `- [${idx + 1}] ${c.title ? `[${c.title}](${c.url})` : c.url}`);
        const citationsText = `\n\nì°¸ê³ ë¬¸í—Œ:\n${citationLines.join('\n')}`;
        controller.enqueue(encoder.encode(citationsText));
      }
    },
  });

  return new Response(response.body?.pipeThrough(transformStream), {
    status: 200,
    headers: { 'Content-Type': 'text/plain; charset=utf-8' }
  });
}